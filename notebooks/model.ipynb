{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer notre RNN pour faire la catégorisation des genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /tf/notebooks/notebooks\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "version = 3\n",
    "df = pd.read_csv('clean_data/v{version}_audio_features_30s_equal.csv'.format(version=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Dictionnaire clef valeur du label_encoded:label\n",
    "label_dict = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Y = df['label_encoded']\n",
    "X = df.drop(['label', 'label_encoded'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# transform Y to a ndarray\n",
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# extract X_val and Y_val from X_test and Y_test (0.5)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# save train, val and test into a csv\n",
    "pd.DataFrame(X_train).to_csv('clean_data/v{version}_X_train.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(X_val).to_csv('clean_data/v{version}_X_val.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(X_test).to_csv('clean_data/v{version}_X_test.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_train).to_csv('clean_data/v{version}_Y_train.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_val).to_csv('clean_data/v{version}_Y_val.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_test).to_csv('clean_data/v{version}_Y_test.csv'.format(version=version), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM RNN\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "number_labels = len(label_dict)\n",
    "\n",
    "# X_train_traited = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test_traited = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "# X_val_traited = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "\n",
    "X_train_traited = X_train\n",
    "X_test_traited = X_test\n",
    "X_val_traited = X_val\n",
    "\n",
    "Y_train_traited = to_categorical(Y_train, num_classes=number_labels)\n",
    "Y_test_traited = to_categorical(Y_test, num_classes=number_labels)\n",
    "Y_val_traited = to_categorical(Y_val, num_classes=number_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_traited.shape, X_test_traited.shape, X_val_traited.shape, Y_train_traited.shape, Y_test_traited.shape, Y_val_traited.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Flatten\n",
    "# model V1\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model V1\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "# model V3\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_traited, Y_train_traited, epochs=250, batch_size=32, validation_data=(X_val_traited, Y_val_traited), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('./models/v{version}_model.h5'.format(version=version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_traited, Y_test_traited, verbose=1)\n",
    "print(f'Accuracy model: {accuracy*100}%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
