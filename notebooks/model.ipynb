{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer notre RNN pour faire la catégorisation des genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/notebooks\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /tf/notebooks/notebooks\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "version = 3\n",
    "df = pd.read_csv('clean_data/v{version}_audio_features_30s_equal.csv'.format(version=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Dictionnaire clef valeur du label_encoded:label\n",
    "label_dict = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'blues',\n",
       " 1: 'classical',\n",
       " 2: 'country',\n",
       " 3: 'disco',\n",
       " 4: 'hiphop',\n",
       " 5: 'jazz',\n",
       " 6: 'metal',\n",
       " 7: 'pop',\n",
       " 8: 'reggae',\n",
       " 9: 'rock'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Y = df['label_encoded']\n",
    "X = df.drop(['label', 'label_encoded'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# transform Y to a ndarray\n",
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# extract X_val and Y_val from X_test and Y_test (0.5)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# save train, val and test into a csv\n",
    "pd.DataFrame(X_train).to_csv('clean_data/v{version}_X_train.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(X_val).to_csv('clean_data/v{version}_X_val.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(X_test).to_csv('clean_data/v{version}_X_test.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_train).to_csv('clean_data/v{version}_Y_train.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_val).to_csv('clean_data/v{version}_Y_val.csv'.format(version=version), index=False)\n",
    "pd.DataFrame(Y_test).to_csv('clean_data/v{version}_Y_test.csv'.format(version=version), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((930, 16), (310, 16), (310, 16), (930,), (310,), (310,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 11:39:36.961087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-16 11:39:36.961137: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-16 11:39:36.961160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-16 11:39:36.967894: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Reshape for LSTM RNN\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "number_labels = len(label_dict)\n",
    "\n",
    "# X_train_traited = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test_traited = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "# X_val_traited = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "\n",
    "X_train_traited = X_train\n",
    "X_test_traited = X_test\n",
    "X_val_traited = X_val\n",
    "\n",
    "Y_train_traited = to_categorical(Y_train, num_classes=number_labels)\n",
    "Y_test_traited = to_categorical(Y_test, num_classes=number_labels)\n",
    "Y_val_traited = to_categorical(Y_val, num_classes=number_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((930, 16), (310, 16), (310, 16), (930, 10), (310, 10), (310, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_traited.shape, X_test_traited.shape, X_val_traited.shape, Y_train_traited.shape, Y_test_traited.shape, Y_val_traited.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 128)               2176      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11082 (43.29 KB)\n",
      "Trainable params: 11082 (43.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define RNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Flatten\n",
    "# model V1\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model V1\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "# model V3\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(number_labels, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "30/30 [==============================] - 1s 15ms/step - loss: 2.2071 - accuracy: 0.1753 - val_loss: 2.0158 - val_accuracy: 0.3065\n",
      "Epoch 2/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.9371 - accuracy: 0.3366 - val_loss: 1.8294 - val_accuracy: 0.3613\n",
      "Epoch 3/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.7659 - accuracy: 0.3903 - val_loss: 1.7031 - val_accuracy: 0.4258\n",
      "Epoch 4/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.6402 - accuracy: 0.4409 - val_loss: 1.6152 - val_accuracy: 0.4452\n",
      "Epoch 5/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.5731 - accuracy: 0.4710 - val_loss: 1.5703 - val_accuracy: 0.4839\n",
      "Epoch 6/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.5211 - accuracy: 0.4645 - val_loss: 1.5296 - val_accuracy: 0.4871\n",
      "Epoch 7/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.4763 - accuracy: 0.4860 - val_loss: 1.5090 - val_accuracy: 0.4935\n",
      "Epoch 8/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.4393 - accuracy: 0.5086 - val_loss: 1.4853 - val_accuracy: 0.5032\n",
      "Epoch 9/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.4067 - accuracy: 0.5376 - val_loss: 1.4483 - val_accuracy: 0.5194\n",
      "Epoch 10/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.3918 - accuracy: 0.5075 - val_loss: 1.4351 - val_accuracy: 0.5032\n",
      "Epoch 11/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3509 - accuracy: 0.5505 - val_loss: 1.4187 - val_accuracy: 0.5161\n",
      "Epoch 12/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3176 - accuracy: 0.5441 - val_loss: 1.3976 - val_accuracy: 0.5032\n",
      "Epoch 13/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3060 - accuracy: 0.5473 - val_loss: 1.3789 - val_accuracy: 0.5290\n",
      "Epoch 14/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.2809 - accuracy: 0.5473 - val_loss: 1.3812 - val_accuracy: 0.5194\n",
      "Epoch 15/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2571 - accuracy: 0.5516 - val_loss: 1.3653 - val_accuracy: 0.5290\n",
      "Epoch 16/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2459 - accuracy: 0.5645 - val_loss: 1.3518 - val_accuracy: 0.5323\n",
      "Epoch 17/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2307 - accuracy: 0.5645 - val_loss: 1.3541 - val_accuracy: 0.5290\n",
      "Epoch 18/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1855 - accuracy: 0.5989 - val_loss: 1.3384 - val_accuracy: 0.5290\n",
      "Epoch 19/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1871 - accuracy: 0.5946 - val_loss: 1.3456 - val_accuracy: 0.5097\n",
      "Epoch 20/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1649 - accuracy: 0.6043 - val_loss: 1.3126 - val_accuracy: 0.5387\n",
      "Epoch 21/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1415 - accuracy: 0.5946 - val_loss: 1.3025 - val_accuracy: 0.5452\n",
      "Epoch 22/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1398 - accuracy: 0.6065 - val_loss: 1.2998 - val_accuracy: 0.5323\n",
      "Epoch 23/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1074 - accuracy: 0.6312 - val_loss: 1.3133 - val_accuracy: 0.5323\n",
      "Epoch 24/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1118 - accuracy: 0.6161 - val_loss: 1.2975 - val_accuracy: 0.5516\n",
      "Epoch 25/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0924 - accuracy: 0.6312 - val_loss: 1.2807 - val_accuracy: 0.5484\n",
      "Epoch 26/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0711 - accuracy: 0.6484 - val_loss: 1.2757 - val_accuracy: 0.5548\n",
      "Epoch 27/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0490 - accuracy: 0.6366 - val_loss: 1.2936 - val_accuracy: 0.5516\n",
      "Epoch 28/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0405 - accuracy: 0.6430 - val_loss: 1.2735 - val_accuracy: 0.5581\n",
      "Epoch 29/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0435 - accuracy: 0.6441 - val_loss: 1.2781 - val_accuracy: 0.5645\n",
      "Epoch 30/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0129 - accuracy: 0.6548 - val_loss: 1.2621 - val_accuracy: 0.5871\n",
      "Epoch 31/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9916 - accuracy: 0.6624 - val_loss: 1.2617 - val_accuracy: 0.5613\n",
      "Epoch 32/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0052 - accuracy: 0.6591 - val_loss: 1.2572 - val_accuracy: 0.5742\n",
      "Epoch 33/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9714 - accuracy: 0.6839 - val_loss: 1.2517 - val_accuracy: 0.5677\n",
      "Epoch 34/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9525 - accuracy: 0.6688 - val_loss: 1.2542 - val_accuracy: 0.5742\n",
      "Epoch 35/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9357 - accuracy: 0.6817 - val_loss: 1.2394 - val_accuracy: 0.5871\n",
      "Epoch 36/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.9386 - accuracy: 0.6839 - val_loss: 1.2390 - val_accuracy: 0.5774\n",
      "Epoch 37/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9278 - accuracy: 0.6871 - val_loss: 1.2410 - val_accuracy: 0.5903\n",
      "Epoch 38/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.8946 - accuracy: 0.6946 - val_loss: 1.2476 - val_accuracy: 0.5935\n",
      "Epoch 39/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9155 - accuracy: 0.6968 - val_loss: 1.2453 - val_accuracy: 0.5871\n",
      "Epoch 40/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8794 - accuracy: 0.7043 - val_loss: 1.2322 - val_accuracy: 0.6000\n",
      "Epoch 41/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8931 - accuracy: 0.6957 - val_loss: 1.2279 - val_accuracy: 0.5935\n",
      "Epoch 42/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8699 - accuracy: 0.7022 - val_loss: 1.2471 - val_accuracy: 0.5774\n",
      "Epoch 43/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8514 - accuracy: 0.7118 - val_loss: 1.2368 - val_accuracy: 0.5968\n",
      "Epoch 44/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8637 - accuracy: 0.7161 - val_loss: 1.2310 - val_accuracy: 0.6000\n",
      "Epoch 45/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.8480 - accuracy: 0.7043 - val_loss: 1.2380 - val_accuracy: 0.5871\n",
      "Epoch 46/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8443 - accuracy: 0.7194 - val_loss: 1.2364 - val_accuracy: 0.5935\n",
      "Epoch 47/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8159 - accuracy: 0.7376 - val_loss: 1.2193 - val_accuracy: 0.5968\n",
      "Epoch 48/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8144 - accuracy: 0.7183 - val_loss: 1.2421 - val_accuracy: 0.6000\n",
      "Epoch 49/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8183 - accuracy: 0.7290 - val_loss: 1.2350 - val_accuracy: 0.5903\n",
      "Epoch 50/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7926 - accuracy: 0.7344 - val_loss: 1.2368 - val_accuracy: 0.6032\n",
      "Epoch 51/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8058 - accuracy: 0.7280 - val_loss: 1.2458 - val_accuracy: 0.5839\n",
      "Epoch 52/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7981 - accuracy: 0.7473 - val_loss: 1.2402 - val_accuracy: 0.5935\n",
      "Epoch 53/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7754 - accuracy: 0.7323 - val_loss: 1.2252 - val_accuracy: 0.5935\n",
      "Epoch 54/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7745 - accuracy: 0.7333 - val_loss: 1.2399 - val_accuracy: 0.5935\n",
      "Epoch 55/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7622 - accuracy: 0.7505 - val_loss: 1.2495 - val_accuracy: 0.6032\n",
      "Epoch 56/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7643 - accuracy: 0.7323 - val_loss: 1.2384 - val_accuracy: 0.5903\n",
      "Epoch 57/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7352 - accuracy: 0.7484 - val_loss: 1.2131 - val_accuracy: 0.6000\n",
      "Epoch 58/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7424 - accuracy: 0.7581 - val_loss: 1.2289 - val_accuracy: 0.6032\n",
      "Epoch 59/250\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7394 - accuracy: 0.7570 - val_loss: 1.2287 - val_accuracy: 0.6161\n",
      "Epoch 60/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6978 - accuracy: 0.7699 - val_loss: 1.2279 - val_accuracy: 0.6065\n",
      "Epoch 61/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7003 - accuracy: 0.7785 - val_loss: 1.2247 - val_accuracy: 0.6097\n",
      "Epoch 62/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7019 - accuracy: 0.7710 - val_loss: 1.2419 - val_accuracy: 0.6065\n",
      "Epoch 63/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.7774 - val_loss: 1.2332 - val_accuracy: 0.6129\n",
      "Epoch 64/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6890 - accuracy: 0.7570 - val_loss: 1.2541 - val_accuracy: 0.6226\n",
      "Epoch 65/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6826 - accuracy: 0.7710 - val_loss: 1.2498 - val_accuracy: 0.6065\n",
      "Epoch 66/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7143 - accuracy: 0.7505 - val_loss: 1.2325 - val_accuracy: 0.6065\n",
      "Epoch 67/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6740 - accuracy: 0.7710 - val_loss: 1.2307 - val_accuracy: 0.6065\n",
      "Epoch 68/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.7839 - val_loss: 1.2261 - val_accuracy: 0.6065\n",
      "Epoch 69/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.7871 - val_loss: 1.2553 - val_accuracy: 0.6065\n",
      "Epoch 70/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.7935 - val_loss: 1.2283 - val_accuracy: 0.6161\n",
      "Epoch 71/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.7796 - val_loss: 1.2671 - val_accuracy: 0.6129\n",
      "Epoch 72/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6552 - accuracy: 0.7796 - val_loss: 1.2489 - val_accuracy: 0.6065\n",
      "Epoch 73/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6340 - accuracy: 0.7925 - val_loss: 1.2530 - val_accuracy: 0.6032\n",
      "Epoch 74/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6012 - accuracy: 0.8075 - val_loss: 1.2857 - val_accuracy: 0.6194\n",
      "Epoch 75/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6108 - accuracy: 0.8054 - val_loss: 1.2683 - val_accuracy: 0.6000\n",
      "Epoch 76/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.7871 - val_loss: 1.2490 - val_accuracy: 0.6290\n",
      "Epoch 77/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.8054 - val_loss: 1.2637 - val_accuracy: 0.6290\n",
      "Epoch 78/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.7882 - val_loss: 1.2341 - val_accuracy: 0.6129\n",
      "Epoch 79/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5984 - accuracy: 0.7989 - val_loss: 1.3071 - val_accuracy: 0.6258\n",
      "Epoch 80/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.8151 - val_loss: 1.2765 - val_accuracy: 0.6097\n",
      "Epoch 81/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6044 - accuracy: 0.8054 - val_loss: 1.2648 - val_accuracy: 0.6258\n",
      "Epoch 82/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5473 - accuracy: 0.8183 - val_loss: 1.2858 - val_accuracy: 0.6032\n",
      "Epoch 83/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5659 - accuracy: 0.8075 - val_loss: 1.2682 - val_accuracy: 0.6161\n",
      "Epoch 84/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5610 - accuracy: 0.8075 - val_loss: 1.2950 - val_accuracy: 0.6290\n",
      "Epoch 85/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5750 - accuracy: 0.8108 - val_loss: 1.2671 - val_accuracy: 0.6226\n",
      "Epoch 86/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5455 - accuracy: 0.8237 - val_loss: 1.2868 - val_accuracy: 0.6161\n",
      "Epoch 87/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.8151 - val_loss: 1.2975 - val_accuracy: 0.6161\n",
      "Epoch 88/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5485 - accuracy: 0.8172 - val_loss: 1.2954 - val_accuracy: 0.6258\n",
      "Epoch 89/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5523 - accuracy: 0.8097 - val_loss: 1.3219 - val_accuracy: 0.6097\n",
      "Epoch 90/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5219 - accuracy: 0.8409 - val_loss: 1.2925 - val_accuracy: 0.6194\n",
      "Epoch 91/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.8183 - val_loss: 1.3076 - val_accuracy: 0.6226\n",
      "Epoch 92/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5378 - accuracy: 0.8355 - val_loss: 1.3093 - val_accuracy: 0.6161\n",
      "Epoch 93/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5218 - accuracy: 0.8419 - val_loss: 1.3286 - val_accuracy: 0.6065\n",
      "Epoch 94/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5078 - accuracy: 0.8366 - val_loss: 1.3096 - val_accuracy: 0.6161\n",
      "Epoch 95/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4952 - accuracy: 0.8355 - val_loss: 1.3238 - val_accuracy: 0.6419\n",
      "Epoch 96/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5107 - accuracy: 0.8355 - val_loss: 1.3482 - val_accuracy: 0.6032\n",
      "Epoch 97/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.8355 - val_loss: 1.3127 - val_accuracy: 0.6161\n",
      "Epoch 98/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5070 - accuracy: 0.8269 - val_loss: 1.3340 - val_accuracy: 0.6194\n",
      "Epoch 99/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5105 - accuracy: 0.8387 - val_loss: 1.3252 - val_accuracy: 0.6194\n",
      "Epoch 100/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4711 - accuracy: 0.8473 - val_loss: 1.3486 - val_accuracy: 0.6258\n",
      "Epoch 101/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5033 - accuracy: 0.8290 - val_loss: 1.3135 - val_accuracy: 0.6290\n",
      "Epoch 102/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.8602 - val_loss: 1.3485 - val_accuracy: 0.6355\n",
      "Epoch 103/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4949 - accuracy: 0.8473 - val_loss: 1.3304 - val_accuracy: 0.6387\n",
      "Epoch 104/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4868 - accuracy: 0.8376 - val_loss: 1.3445 - val_accuracy: 0.6161\n",
      "Epoch 105/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4900 - accuracy: 0.8269 - val_loss: 1.3386 - val_accuracy: 0.6258\n",
      "Epoch 106/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4441 - accuracy: 0.8570 - val_loss: 1.3452 - val_accuracy: 0.6290\n",
      "Epoch 107/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5186 - accuracy: 0.8226 - val_loss: 1.3453 - val_accuracy: 0.6194\n",
      "Epoch 108/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.8419 - val_loss: 1.3361 - val_accuracy: 0.6000\n",
      "Epoch 109/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4452 - accuracy: 0.8656 - val_loss: 1.3745 - val_accuracy: 0.6226\n",
      "Epoch 110/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4600 - accuracy: 0.8462 - val_loss: 1.3607 - val_accuracy: 0.6387\n",
      "Epoch 111/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4540 - accuracy: 0.8430 - val_loss: 1.3626 - val_accuracy: 0.6161\n",
      "Epoch 112/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.8505 - val_loss: 1.3857 - val_accuracy: 0.6161\n",
      "Epoch 113/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4474 - accuracy: 0.8505 - val_loss: 1.3793 - val_accuracy: 0.6161\n",
      "Epoch 114/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4350 - accuracy: 0.8591 - val_loss: 1.3797 - val_accuracy: 0.6194\n",
      "Epoch 115/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8656 - val_loss: 1.3891 - val_accuracy: 0.6323\n",
      "Epoch 116/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4147 - accuracy: 0.8634 - val_loss: 1.3825 - val_accuracy: 0.6290\n",
      "Epoch 117/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4154 - accuracy: 0.8581 - val_loss: 1.3956 - val_accuracy: 0.6258\n",
      "Epoch 118/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4002 - accuracy: 0.8742 - val_loss: 1.4049 - val_accuracy: 0.6226\n",
      "Epoch 119/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3928 - accuracy: 0.8742 - val_loss: 1.4202 - val_accuracy: 0.6452\n",
      "Epoch 120/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8634 - val_loss: 1.4132 - val_accuracy: 0.6290\n",
      "Epoch 121/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.8774 - val_loss: 1.4106 - val_accuracy: 0.6258\n",
      "Epoch 122/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3946 - accuracy: 0.8699 - val_loss: 1.4285 - val_accuracy: 0.6290\n",
      "Epoch 123/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3711 - accuracy: 0.8882 - val_loss: 1.4049 - val_accuracy: 0.6258\n",
      "Epoch 124/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.8925 - val_loss: 1.4127 - val_accuracy: 0.6226\n",
      "Epoch 125/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.8882 - val_loss: 1.4442 - val_accuracy: 0.6226\n",
      "Epoch 126/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8581 - val_loss: 1.4300 - val_accuracy: 0.6226\n",
      "Epoch 127/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.8903 - val_loss: 1.4381 - val_accuracy: 0.5968\n",
      "Epoch 128/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.8882 - val_loss: 1.4573 - val_accuracy: 0.6097\n",
      "Epoch 129/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3645 - accuracy: 0.8839 - val_loss: 1.4304 - val_accuracy: 0.6161\n",
      "Epoch 130/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3651 - accuracy: 0.8763 - val_loss: 1.4180 - val_accuracy: 0.6355\n",
      "Epoch 131/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3565 - accuracy: 0.8849 - val_loss: 1.4293 - val_accuracy: 0.6226\n",
      "Epoch 132/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3558 - accuracy: 0.8839 - val_loss: 1.4207 - val_accuracy: 0.6323\n",
      "Epoch 133/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3471 - accuracy: 0.8860 - val_loss: 1.4359 - val_accuracy: 0.6290\n",
      "Epoch 134/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.8946 - val_loss: 1.4385 - val_accuracy: 0.6258\n",
      "Epoch 135/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3377 - accuracy: 0.9000 - val_loss: 1.4449 - val_accuracy: 0.6419\n",
      "Epoch 136/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3507 - accuracy: 0.8957 - val_loss: 1.4705 - val_accuracy: 0.6290\n",
      "Epoch 137/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3278 - accuracy: 0.8978 - val_loss: 1.4568 - val_accuracy: 0.6194\n",
      "Epoch 138/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3410 - accuracy: 0.8968 - val_loss: 1.4657 - val_accuracy: 0.6323\n",
      "Epoch 139/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.9022 - val_loss: 1.5334 - val_accuracy: 0.6194\n",
      "Epoch 140/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3525 - accuracy: 0.8903 - val_loss: 1.4937 - val_accuracy: 0.6194\n",
      "Epoch 141/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3248 - accuracy: 0.8914 - val_loss: 1.5201 - val_accuracy: 0.6290\n",
      "Epoch 142/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3273 - accuracy: 0.8860 - val_loss: 1.4952 - val_accuracy: 0.6129\n",
      "Epoch 143/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3057 - accuracy: 0.9086 - val_loss: 1.5174 - val_accuracy: 0.6226\n",
      "Epoch 144/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 0.9043 - val_loss: 1.5050 - val_accuracy: 0.6065\n",
      "Epoch 145/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3193 - accuracy: 0.8989 - val_loss: 1.5623 - val_accuracy: 0.5968\n",
      "Epoch 146/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3033 - accuracy: 0.9054 - val_loss: 1.5250 - val_accuracy: 0.6290\n",
      "Epoch 147/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3069 - accuracy: 0.8925 - val_loss: 1.5020 - val_accuracy: 0.6194\n",
      "Epoch 148/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 0.9129 - val_loss: 1.4869 - val_accuracy: 0.6161\n",
      "Epoch 149/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3028 - accuracy: 0.9075 - val_loss: 1.5121 - val_accuracy: 0.6355\n",
      "Epoch 150/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2965 - accuracy: 0.9194 - val_loss: 1.5354 - val_accuracy: 0.6129\n",
      "Epoch 151/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3102 - accuracy: 0.9043 - val_loss: 1.5284 - val_accuracy: 0.6226\n",
      "Epoch 152/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8871 - val_loss: 1.5572 - val_accuracy: 0.6065\n",
      "Epoch 153/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2957 - accuracy: 0.9204 - val_loss: 1.5653 - val_accuracy: 0.6194\n",
      "Epoch 154/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3110 - accuracy: 0.8914 - val_loss: 1.5406 - val_accuracy: 0.6129\n",
      "Epoch 155/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2892 - accuracy: 0.9140 - val_loss: 1.5606 - val_accuracy: 0.6387\n",
      "Epoch 156/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2968 - accuracy: 0.9129 - val_loss: 1.5654 - val_accuracy: 0.6226\n",
      "Epoch 157/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2983 - accuracy: 0.9118 - val_loss: 1.5465 - val_accuracy: 0.6226\n",
      "Epoch 158/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2932 - accuracy: 0.9054 - val_loss: 1.5943 - val_accuracy: 0.6032\n",
      "Epoch 159/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2695 - accuracy: 0.9280 - val_loss: 1.5734 - val_accuracy: 0.6161\n",
      "Epoch 160/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2779 - accuracy: 0.9043 - val_loss: 1.5735 - val_accuracy: 0.6258\n",
      "Epoch 161/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2813 - accuracy: 0.9065 - val_loss: 1.5730 - val_accuracy: 0.6258\n",
      "Epoch 162/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2722 - accuracy: 0.9204 - val_loss: 1.6150 - val_accuracy: 0.6161\n",
      "Epoch 163/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2485 - accuracy: 0.9237 - val_loss: 1.6287 - val_accuracy: 0.6065\n",
      "Epoch 164/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2668 - accuracy: 0.9172 - val_loss: 1.6109 - val_accuracy: 0.6161\n",
      "Epoch 165/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2729 - accuracy: 0.9161 - val_loss: 1.5880 - val_accuracy: 0.6097\n",
      "Epoch 166/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2481 - accuracy: 0.9280 - val_loss: 1.6528 - val_accuracy: 0.6258\n",
      "Epoch 167/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2562 - accuracy: 0.9290 - val_loss: 1.5929 - val_accuracy: 0.6097\n",
      "Epoch 168/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2605 - accuracy: 0.9247 - val_loss: 1.6057 - val_accuracy: 0.6065\n",
      "Epoch 169/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2783 - accuracy: 0.9129 - val_loss: 1.6215 - val_accuracy: 0.6000\n",
      "Epoch 170/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.9237 - val_loss: 1.6593 - val_accuracy: 0.6129\n",
      "Epoch 171/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2379 - accuracy: 0.9290 - val_loss: 1.6144 - val_accuracy: 0.6065\n",
      "Epoch 172/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2472 - accuracy: 0.9140 - val_loss: 1.6616 - val_accuracy: 0.6258\n",
      "Epoch 173/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2396 - accuracy: 0.9258 - val_loss: 1.6082 - val_accuracy: 0.6258\n",
      "Epoch 174/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.9323 - val_loss: 1.6076 - val_accuracy: 0.6129\n",
      "Epoch 175/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9355 - val_loss: 1.6559 - val_accuracy: 0.6065\n",
      "Epoch 176/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2076 - accuracy: 0.9398 - val_loss: 1.6589 - val_accuracy: 0.6129\n",
      "Epoch 177/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2224 - accuracy: 0.9409 - val_loss: 1.6731 - val_accuracy: 0.6161\n",
      "Epoch 178/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2320 - accuracy: 0.9323 - val_loss: 1.7033 - val_accuracy: 0.6194\n",
      "Epoch 179/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2288 - accuracy: 0.9355 - val_loss: 1.6897 - val_accuracy: 0.6323\n",
      "Epoch 180/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9312 - val_loss: 1.7253 - val_accuracy: 0.6161\n",
      "Epoch 181/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2196 - accuracy: 0.9441 - val_loss: 1.6848 - val_accuracy: 0.6065\n",
      "Epoch 182/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2139 - accuracy: 0.9441 - val_loss: 1.6776 - val_accuracy: 0.6161\n",
      "Epoch 183/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2376 - accuracy: 0.9140 - val_loss: 1.6611 - val_accuracy: 0.6097\n",
      "Epoch 184/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2090 - accuracy: 0.9441 - val_loss: 1.7317 - val_accuracy: 0.5968\n",
      "Epoch 185/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2180 - accuracy: 0.9452 - val_loss: 1.6850 - val_accuracy: 0.6065\n",
      "Epoch 186/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9226 - val_loss: 1.7256 - val_accuracy: 0.6129\n",
      "Epoch 187/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2204 - accuracy: 0.9290 - val_loss: 1.7412 - val_accuracy: 0.6161\n",
      "Epoch 188/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2487 - accuracy: 0.9108 - val_loss: 1.6810 - val_accuracy: 0.6194\n",
      "Epoch 189/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2134 - accuracy: 0.9409 - val_loss: 1.6726 - val_accuracy: 0.6161\n",
      "Epoch 190/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2191 - accuracy: 0.9376 - val_loss: 1.7453 - val_accuracy: 0.6194\n",
      "Epoch 191/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1998 - accuracy: 0.9462 - val_loss: 1.7229 - val_accuracy: 0.6065\n",
      "Epoch 192/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1911 - accuracy: 0.9559 - val_loss: 1.7644 - val_accuracy: 0.6065\n",
      "Epoch 193/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2120 - accuracy: 0.9312 - val_loss: 1.7592 - val_accuracy: 0.6129\n",
      "Epoch 194/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 0.9387 - val_loss: 1.7418 - val_accuracy: 0.6161\n",
      "Epoch 195/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2161 - accuracy: 0.9387 - val_loss: 1.7761 - val_accuracy: 0.6161\n",
      "Epoch 196/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9419 - val_loss: 1.7832 - val_accuracy: 0.6161\n",
      "Epoch 197/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.9409 - val_loss: 1.7706 - val_accuracy: 0.6226\n",
      "Epoch 198/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2050 - accuracy: 0.9366 - val_loss: 1.7304 - val_accuracy: 0.6258\n",
      "Epoch 199/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1997 - accuracy: 0.9462 - val_loss: 1.7350 - val_accuracy: 0.6194\n",
      "Epoch 200/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1895 - accuracy: 0.9473 - val_loss: 1.7830 - val_accuracy: 0.6258\n",
      "Epoch 201/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1702 - accuracy: 0.9570 - val_loss: 1.8014 - val_accuracy: 0.6194\n",
      "Epoch 202/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1982 - accuracy: 0.9409 - val_loss: 1.8036 - val_accuracy: 0.6065\n",
      "Epoch 203/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1878 - accuracy: 0.9376 - val_loss: 1.7995 - val_accuracy: 0.6129\n",
      "Epoch 204/250\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1818 - accuracy: 0.9516 - val_loss: 1.7813 - val_accuracy: 0.6097\n",
      "Epoch 205/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 0.9559 - val_loss: 1.8039 - val_accuracy: 0.6323\n",
      "Epoch 206/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1814 - accuracy: 0.9430 - val_loss: 1.8246 - val_accuracy: 0.6032\n",
      "Epoch 207/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1954 - accuracy: 0.9344 - val_loss: 1.8150 - val_accuracy: 0.6194\n",
      "Epoch 208/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2229 - accuracy: 0.9247 - val_loss: 1.7871 - val_accuracy: 0.6226\n",
      "Epoch 209/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9495 - val_loss: 1.8532 - val_accuracy: 0.6065\n",
      "Epoch 210/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1897 - accuracy: 0.9452 - val_loss: 1.8861 - val_accuracy: 0.6097\n",
      "Epoch 211/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1751 - accuracy: 0.9452 - val_loss: 1.8020 - val_accuracy: 0.6226\n",
      "Epoch 212/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1864 - accuracy: 0.9398 - val_loss: 1.8690 - val_accuracy: 0.6194\n",
      "Epoch 213/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1761 - accuracy: 0.9484 - val_loss: 1.8441 - val_accuracy: 0.6097\n",
      "Epoch 214/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1630 - accuracy: 0.9527 - val_loss: 1.8441 - val_accuracy: 0.6032\n",
      "Epoch 215/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 0.9430 - val_loss: 1.8282 - val_accuracy: 0.6290\n",
      "Epoch 216/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1784 - accuracy: 0.9441 - val_loss: 1.8653 - val_accuracy: 0.6032\n",
      "Epoch 217/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1663 - accuracy: 0.9473 - val_loss: 1.8391 - val_accuracy: 0.6226\n",
      "Epoch 218/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.9624 - val_loss: 1.8261 - val_accuracy: 0.6129\n",
      "Epoch 219/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1683 - accuracy: 0.9602 - val_loss: 1.8261 - val_accuracy: 0.6161\n",
      "Epoch 220/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1591 - accuracy: 0.9527 - val_loss: 1.9161 - val_accuracy: 0.6258\n",
      "Epoch 221/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9430 - val_loss: 1.9014 - val_accuracy: 0.6065\n",
      "Epoch 222/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1647 - accuracy: 0.9452 - val_loss: 1.8821 - val_accuracy: 0.6097\n",
      "Epoch 223/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1529 - accuracy: 0.9634 - val_loss: 1.8615 - val_accuracy: 0.6194\n",
      "Epoch 224/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9613 - val_loss: 1.8994 - val_accuracy: 0.6226\n",
      "Epoch 225/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1504 - accuracy: 0.9645 - val_loss: 1.8632 - val_accuracy: 0.6194\n",
      "Epoch 226/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9602 - val_loss: 1.8773 - val_accuracy: 0.6194\n",
      "Epoch 227/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1579 - accuracy: 0.9516 - val_loss: 1.9725 - val_accuracy: 0.6000\n",
      "Epoch 228/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1774 - accuracy: 0.9387 - val_loss: 1.8738 - val_accuracy: 0.6161\n",
      "Epoch 229/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1511 - accuracy: 0.9559 - val_loss: 1.8506 - val_accuracy: 0.6194\n",
      "Epoch 230/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1501 - accuracy: 0.9602 - val_loss: 1.8574 - val_accuracy: 0.6097\n",
      "Epoch 231/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.9656 - val_loss: 1.9701 - val_accuracy: 0.6065\n",
      "Epoch 232/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 0.9570 - val_loss: 1.9005 - val_accuracy: 0.6129\n",
      "Epoch 233/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9624 - val_loss: 1.8802 - val_accuracy: 0.6194\n",
      "Epoch 234/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9548 - val_loss: 1.9556 - val_accuracy: 0.6000\n",
      "Epoch 235/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9613 - val_loss: 1.9043 - val_accuracy: 0.6194\n",
      "Epoch 236/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1564 - accuracy: 0.9591 - val_loss: 1.8850 - val_accuracy: 0.6000\n",
      "Epoch 237/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.9688 - val_loss: 1.9009 - val_accuracy: 0.6161\n",
      "Epoch 238/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9731 - val_loss: 1.9630 - val_accuracy: 0.6097\n",
      "Epoch 239/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.9677 - val_loss: 1.9471 - val_accuracy: 0.6290\n",
      "Epoch 240/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9559 - val_loss: 1.9499 - val_accuracy: 0.6258\n",
      "Epoch 241/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9591 - val_loss: 1.9649 - val_accuracy: 0.6258\n",
      "Epoch 242/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1405 - accuracy: 0.9570 - val_loss: 1.9553 - val_accuracy: 0.6097\n",
      "Epoch 243/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1278 - accuracy: 0.9634 - val_loss: 1.9894 - val_accuracy: 0.6129\n",
      "Epoch 244/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1294 - accuracy: 0.9688 - val_loss: 1.9748 - val_accuracy: 0.6161\n",
      "Epoch 245/250\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1678 - accuracy: 0.9473 - val_loss: 1.9854 - val_accuracy: 0.6161\n",
      "Epoch 246/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1151 - accuracy: 0.9753 - val_loss: 1.9393 - val_accuracy: 0.6161\n",
      "Epoch 247/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9656 - val_loss: 2.0224 - val_accuracy: 0.6161\n",
      "Epoch 248/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1368 - accuracy: 0.9667 - val_loss: 1.9867 - val_accuracy: 0.6129\n",
      "Epoch 249/250\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9613 - val_loss: 2.0671 - val_accuracy: 0.6226\n",
      "Epoch 250/250\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9656 - val_loss: 1.9824 - val_accuracy: 0.6226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa3842ff1d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_traited, Y_train_traited, epochs=250, batch_size=32, validation_data=(X_val_traited, Y_val_traited), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save('./models/v{version}_model.h5'.format(version=version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step - loss: 2.0743 - accuracy: 0.6065\n",
      "Accuracy model: 60.64516305923462%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_traited, Y_test_traited, verbose=1)\n",
    "print(f'Accuracy model: {accuracy*100}%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
